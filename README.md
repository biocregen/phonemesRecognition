# Установка 
1.
```
  git clone https://github.com/L1TV1N/AI-audio.git
  cd AI-audio
  pip install -r requirements.txt
```
2.  Установите одну из моделей с *google drive*:
   - [*vosk-model-v1*](https://drive.google.com/file/d/1kM-yLf9z0mDhCyyyB1EhL0SFPEjnC0iB/view?usp=sharing) - для быстрой работы, малая модель
   - [*vosk-model-v2*](https://drive.google.com/file/d/1ROT1320jIrBv96qUqX45e2nH20oIO_wB/view?usp=sharing) - для более качественного распознавания речи, дольше работает, хорошо распознает слэнг и различные диалекты, так же ненормативную лексику, большая модель

3.  [Установите Pytorch](https://pytorch.org/get-started/locally/)

PyTorch Build - Stable(2.5.0)
OS - Windows
Package - pip
Language - Python
Compute Platform - CPU

4.  
```
git lfs install

git clone https://huggingface.co/ruaccent/accentuator
```

### Вид директории:
```
AI-audio
│
├── .venv
├── accentuator
├── vosk-model-v1
├── requirements.txt
├── terminal-run.py
└── UI.py

```

### UI.py - основной код с графическим интерфейсом
### terminal-run.py - основной код без графического интерфейса, работа через терминал

# Основные функции **terminal-run.py**:
1. **Выбор микрофона**:
   - Функция `select_microphone()` позволяет пользователю выбрать микрофон из доступных устройств.
   
2. **Запись аудио**:
   - Класс `AudioProcessor` управляет записью аудио с микрофона. При записи аудиопоток сохраняется в формате WAV.
   - Одновременно с записью аудио используется модель распознавания речи Vosk, которая транскрибирует речь в текст и сохраняет его.
   
3. **Транскрипция речи**:
   - Используется библиотека Vosk для преобразования аудио в текст.
   - В транскрипции можно добавлять ударения с помощью библиотеки `RUAccent`, которая расставляет акценты в тексте.

4. **Фонетическая транскрипция**:
   - Функции `transliterate()` и `transliterate_word()` преобразуют транскрипцию с ударениями в фонетическую транскрипцию. Она использует правила преобразования русских букв в латиницу с учётом фонетических особенностей.

5. **Генерация спектрограммы**:
   - Функция `generate_spectrogram()` создает спектрограмму записанного аудио и сохраняет её в виде изображения.
   
6. **Скорость пересечения нуля (ZCR)**:
   - Функция `generate_zcr_graph()` строит график нулевых пересечений (Zero Crossing Rate), который представляет собой количество пересечений сигнала через ось нуля. Это полезно для анализа характеристик звуковых сигналов.

7. **Сохранение результатов**:
   - Результаты транскрипции с ударениями и фонетической транскрипции сохраняются в текстовый файл.
   - Спектрограмма и график ZCR сохраняются в виде изображений.

### Порядок работы:
1. Пользователь выбирает микрофон.
2. Начинается запись аудио.
3. В процессе записи аудио транскрибируется в текст.
4. После завершения записи создаются спектрограмма и график ZCR.
5. Текст проходит обработку для добавления ударений и создания фонетической транскрипции.
6. Все результаты сохраняются на диск: аудиофайл, транскрипция, спектрограмма и график ZCR.

### Используемые библиотеки:
- **pyaudio**: Для захвата аудиопотока с микрофона.
- **wave**: Для работы с WAV-файлами.
- **vosk**: Для распознавания речи.
- **ruaccent**: Для добавления акцентов в русскоязычный текст.
- **matplotlib**: Для построения спектрограммы и графика ZCR.
- **numpy**: Для работы с аудиоданными.

### Основные файлы:
- `output_audio.wav` — аудиофайл записи.
- `transcription.txt` — файл с транскрипцией и фонетической расшифровкой.
- `spectrogram.png` — изображение спектрограммы.
- `zcr_graph.png` — график скорости пересечения нуля.

